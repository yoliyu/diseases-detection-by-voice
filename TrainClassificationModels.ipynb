{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import machineLearning\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import MultiTaskLasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import MultiTaskElasticNet\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit \n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearnex import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def trainModel(datasetPath,dimensionReduction,dimensionReductionComponents):\n",
    "\n",
    "    model_list = []\n",
    "    acc_list = []\n",
    "    pre_list = []\n",
    "    f1_list = []\n",
    "    recall_list = []\n",
    "    espec_list=[]\n",
    "    plot_list = []\n",
    "    foldsNumber = 5\n",
    "    standarized = False\n",
    "    dimensionReduction = dimensionReduction\n",
    "    target = \"healthy\"\n",
    "\n",
    "    dataframe = pd.read_csv(datasetPath)\n",
    "    y = dataframe[target]\n",
    "    X = dataframe.drop([target],axis=1)\n",
    "    print(X.shape)\n",
    "\n",
    "    pca = PCA(n_components=dimensionReductionComponents)\n",
    "    pca.fit(X)\n",
    "    mostImportantFeaturesOfComponents = machineLearning._printMostImportantFeatureOfComponent(pca,list(X.columns))\n",
    "\n",
    "    #LINEAR MODELS\n",
    "    ##RIDGE CLASSIFIER\n",
    "    name = \"RIDGE_CLASSIFIER\"\n",
    "    print(name)\n",
    "    model = RidgeClassifier()\n",
    "    avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    model_list.append(name)\n",
    "    acc_list.append(avg)\n",
    "    pre_list.append(pre)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    plot_list.append(plot) \n",
    "    espec_list.append(espec)\n",
    "\n",
    "    ##LASSO\n",
    "    #print(\"LASSO\")\n",
    "    #model = Lasso(alpha=0.1)\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    ##MULTITASKLASSO\n",
    "    #print(\"MULTITASKLASSO\")\n",
    "    #model = MultiTaskLasso(alpha=0.1)\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    #print(\"ELASTICNET\")\n",
    "    #model = ElasticNet()\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    ##MULTITASKELASTICNET\n",
    "    #print(\"MULTITASKELASTICNET\")\n",
    "    #model = MultiTaskElasticNet(random_state=0)\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    ##LARSLASSO\n",
    "    #print(\"LARSLASSO\")\n",
    "    #model = LassoLars(alpha=0.01)\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    ##ORTOGONAL MATCHING PURSUIT\n",
    "    #print(\"ORTOGONAL MATCHING PURSUIT\")\n",
    "    #model = OrthogonalMatchingPursuit()\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    ##BAYESIAN RIDGE\n",
    "    #print(\"BAYESIAN RIDGE\")\n",
    "    #model = BayesianRidge()\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    ##LOGISTIC REGRESSION\n",
    "    name = \"LOGISTIC_REGRESSION\"\n",
    "    print(name)\n",
    "    model = LogisticRegression(max_iter=2000)\n",
    "    avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    model_list.append(name)\n",
    "    acc_list.append(avg)\n",
    "    pre_list.append(pre)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    plot_list.append(plot) \n",
    "    espec_list.append(espec)\n",
    "\n",
    "    ##TWEEDIE REGRESSOR\n",
    "    #print(\"TWEEDIE REGRESSOR - NORMAL DISTRIBUTION\")\n",
    "    #model = TweedieRegressor(power = 0)\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    #print(\"TWEEDIE REGRESSOR - POISSON DISTRIBUTION\")\n",
    "    #model = TweedieRegressor(power = 1, link='log')\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    #print(\"TWEEDIE REGRESSOR - GAMMA DISTRIBUTION\")\n",
    "    #model = TweedieRegressor(power = 2, link='log')\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    #print(\"TWEEDIE REGRESSOR - INVERSE GAUSSIAN DISTRIBUTION\")\n",
    "    #model = TweedieRegressor(power = 3)\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "\n",
    "    ##PERCEPTRON\n",
    "    name = \"PERCEPTRON\"\n",
    "    print(name)\n",
    "    model = Perceptron()\n",
    "    avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    model_list.append(\"PERCEPTRON\")\n",
    "    acc_list.append(avg)\n",
    "    pre_list.append(pre)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    plot_list.append(plot) \n",
    "    espec_list.append(espec)\n",
    "\n",
    "    ##PASSIVE AGRESSIVE\n",
    "    name = \"PASSIVE_AGRESSIVE\"\n",
    "    print(name)\n",
    "    model = PassiveAggressiveClassifier(max_iter=2000)\n",
    "    avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    model_list.append(name)\n",
    "    acc_list.append(avg)\n",
    "    pre_list.append(pre)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    plot_list.append(plot) \n",
    "    espec_list.append(espec)\n",
    "\n",
    "    #LINEAR AND QUADRATIC DISCRIMINANT ANALYSIS\n",
    "    ##LDA\n",
    "    name = \"LDA\"\n",
    "    print(name)\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    model_list.append(name)\n",
    "    acc_list.append(avg)\n",
    "    pre_list.append(pre)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    plot_list.append(plot) \n",
    "    espec_list.append(espec)\n",
    "\n",
    "    ##QDA\n",
    "    #print(\"QDA\")\n",
    "    #model = QuadraticDiscriminantAnalysis()\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    #KERNEL RIDGE\n",
    "    #print(\"KERNEL RIDGE\")\n",
    "    #model = KernelRidge(alpha=1.0)\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    #SUPPORT VECTOR MACHINE\n",
    "    name = \"SUPPORT_VECTOR_MACHINE\"\n",
    "    print(name)\n",
    "    model = svm.SVC()\n",
    "    avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    model_list.append(name)\n",
    "    acc_list.append(avg)\n",
    "    pre_list.append(pre)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    plot_list.append(plot) \n",
    "    espec_list.append(espec)\n",
    "\n",
    "\n",
    "    #STOCHASTIC GRADIENT DESCENT\n",
    "    name = \"STOCHASTIC_GRADIENT_DESCENT\"\n",
    "    print(name)\n",
    "    model = SGDClassifier(max_iter=2000)\n",
    "    avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    model_list.append(name)\n",
    "    acc_list.append(avg)\n",
    "    pre_list.append(pre)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    plot_list.append(plot) \n",
    "    espec_list.append(espec)\n",
    "\n",
    "    #GAUSSIAN PROCESSES - TODO\n",
    "    #print(\"GAUSSIAN PROCESS\")\n",
    "    #kernel = 1.0 * RBF(1.0)\n",
    "    #model = GaussianProcessClassifier(kernel=kernel, random_state=0)\n",
    "    #avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    #model_list.append(\"GAUSSIAN PROCESS\")\n",
    "    #acc_list.append(avg)\n",
    "    #pre_list.append(pre)\n",
    "    #f1_list.append(f1) plot_list.append(plot) espec_list.append(espec)\n",
    "\n",
    "    #NAIVE BAYES\n",
    "    ##NAIVE BAYES\n",
    "    name = \"NAIVE_BAYES\"\n",
    "    print(name)\n",
    "    model =  GaussianNB()\n",
    "    avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    model_list.append(name)\n",
    "    acc_list.append(avg)\n",
    "    pre_list.append(pre)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    plot_list.append(plot) \n",
    "    espec_list.append(espec)\n",
    "\n",
    "    ##MULTINOMIAL BAYES\n",
    "    #print(\"MULTINOMIAL NAIVE BAYES\")\n",
    "    #model =  MultinomialNB()\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    ##COMPLEMENT BAYES\n",
    "    #print(\"COMPLEMENT NAIVE BAYES\")\n",
    "    #model =  ComplementNB()\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    ##BERNOULLI BAYES\n",
    "    #print(\"BERNOULLINAIVE BAYES\")\n",
    "    #model =  BernoulliNB()\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    ##CATEGORICAL BAYES\n",
    "    #print(\"CATEGORICAL NAIVE BAYES\")\n",
    "    #model =  CategoricalNB()\n",
    "    #machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "\n",
    "    #ENSEMBLE METHODS\n",
    "    ##BAGGING -TODO \n",
    "    name = \"BAGGING\"\n",
    "    print(name)\n",
    "    model = BaggingClassifier()\n",
    "    avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    model_list.append(name)\n",
    "    acc_list.append(avg)\n",
    "    pre_list.append(pre)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    plot_list.append(plot) \n",
    "    espec_list.append(espec)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ##RANDOM FOREST\n",
    "    name = \"RANDOM_FOREST\"\n",
    "    \n",
    "    print(name)\n",
    "    model = RandomForestClassifier()\n",
    "    avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    model_list.append(name)\n",
    "    acc_list.append(avg)\n",
    "    pre_list.append(pre)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    plot_list.append(plot) \n",
    "    espec_list.append(espec)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    ##ADA BOOST\n",
    "    name = \"ADA_BOOST\"\n",
    "    \n",
    "    print(name)\n",
    "    model = AdaBoostClassifier()\n",
    "    avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    model_list.append(name)\n",
    "    acc_list.append(avg)\n",
    "    pre_list.append(pre)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    plot_list.append(plot) \n",
    "    \n",
    "    espec_list.append(espec)\n",
    "\n",
    "\n",
    "    ##GRADIENT BOOST\n",
    "    name = \"GRADIENT_BOOST\"\n",
    "    \n",
    "    print(name)\n",
    "    model = GradientBoostingClassifier()\n",
    "    avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    model_list.append(name)\n",
    "    acc_list.append(avg)\n",
    "    pre_list.append(pre)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    plot_list.append(plot) \n",
    "    espec_list.append(espec)\n",
    "\n",
    "   \n",
    "\n",
    "    ##XBOOST\n",
    "    name = \"XBOOST\"\n",
    "    \n",
    "    print(name)\n",
    "    model = XGBClassifier(use_label_encoder=False)\n",
    "    avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    model_list.append(name)\n",
    "    acc_list.append(avg)\n",
    "    pre_list.append(pre)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    plot_list.append(plot) \n",
    "    espec_list.append(espec)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ##LGBM CLASSIFIER\n",
    "    name = \"LGBM_CLASSIFIER\"\n",
    "    \n",
    "    print(name)\n",
    "    model = LGBMClassifier()\n",
    "    avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    model_list.append(name)\n",
    "    acc_list.append(avg)\n",
    "    pre_list.append(pre)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    plot_list.append(plot) \n",
    "    espec_list.append(espec)\n",
    "   \n",
    "    \n",
    "    \n",
    "\n",
    "    #MULTILAYER PERCEPTRON\n",
    "    #name = \"MULTILAYER_PERCEPTRON\"\n",
    "    #print(name)\n",
    "    #model = MLPClassifier(max_iter=2000)\n",
    "    #avg,pre,f1,recall,espec,plot = machineLearning._trainModel(X,y,foldsNumber,model,standarized,dimensionReduction,dimensionReductionComponents)\n",
    "    #model_list.append(name)\n",
    "    #acc_list.append(avg)\n",
    "    #pre_list.append(pre)\n",
    "    #f1_list.append(f1)\n",
    "    #recall_list.append(recall)\n",
    "    #plot_list.append(plot) \n",
    "    #espec_list.append(espec)\n",
    "\n",
    "\n",
    "    report = pd.DataFrame(np.column_stack([model_list, acc_list,pre_list,f1_list,recall_list,espec_list]),\n",
    "                                                columns=['model', 'accuracy', 'precission','f1','recall','specifity'])\n",
    "    datasetPath2 = datasetPath.replace(\"datasets/\",\"\")\n",
    "    name = datasetPath2.replace(\".csv\",\"\")\n",
    "    stand=\"\"\n",
    "    if standarized == True:\n",
    "        stand = \"standarized\"\n",
    "    else:\n",
    "        stand = \"notstandarized\"\n",
    "    selection = \"\"\n",
    "    if dimensionReduction == 'pca':\n",
    "        selection = 'pca'+\"_\"+ str(dimensionReductionComponents)\n",
    "    else:\n",
    "        selection = 'noselection'\n",
    "    folder = \"./\"+name+\"_\"+str(foldsNumber)+\"cv\"+\"_\"+stand+\"_\"+selection\n",
    "    os.makedirs(folder)\n",
    "    report.to_csv(folder+\"/report.csv\")\n",
    "    mostImportantFeaturesOfComponents.to_csv(folder+\"/features.csv\")\n",
    "    i = 0\n",
    "    for p in plot_list:\n",
    "        im = Image.open(p)\n",
    "        im.save(folder+\"/\"+model_list[i]+\".png\")\n",
    "        p.close()\n",
    "        i += 1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1656, 6375)\n",
      "RIDGE_CLASSIFIER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy : 0.6243712008153459\n",
      "Avg precission : 0.8021457286432161\n",
      "Avg recall : 0.6518982264606403\n",
      "Avg f1 : 0.7189462783175344\n",
      "LOGISTIC_REGRESSION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy : 0.6002402358679431\n",
      "Avg precission : 0.9979899497487438\n",
      "Avg recall : 0.6009638421453195\n",
      "Avg f1 : 0.7501844018278974\n",
      "PERCEPTRON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy : 0.5411494922287338\n",
      "Avg precission : 0.7668341708542713\n",
      "Avg recall : 0.4725095873132127\n",
      "Avg f1 : 0.5844370054777845\n",
      "PASSIVE_AGRESSIVE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy : 0.5314745386379354\n",
      "Avg precission : 0.5024924623115579\n",
      "Avg recall : 0.7910147846519842\n",
      "Avg f1 : 0.4608018512629625\n",
      "LDA\n",
      "Avg accuracy : 0.6545845011465803\n",
      "Avg precission : 0.706819095477387\n",
      "Avg recall : 0.7168687944269339\n",
      "Avg f1 : 0.7112370321851403\n",
      "SUPPORT_VECTOR_MACHINE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy : 0.6014486950824447\n",
      "Avg precission : 1.0\n",
      "Avg recall : 0.6014486950824447\n",
      "Avg f1 : 0.7511306568307561\n",
      "STOCHASTIC_GRADIENT_DESCENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy : 0.6014486950824447\n",
      "Avg precission : 1.0\n",
      "Avg recall : 0.6014486950824447\n",
      "Avg f1 : 0.7511306568307561\n",
      "NAIVE_BAYES\n",
      "Avg accuracy : 0.44745568376223926\n",
      "Avg precission : 0.08230653266331658\n",
      "Avg recall : 0.990909090909091\n",
      "Avg f1 : 0.1504355366892927\n",
      "BAGGING\n",
      "Avg accuracy : 0.797725039129327\n",
      "Avg precission : 0.8443969849246231\n",
      "Avg recall : 0.8305861529178955\n",
      "Avg f1 : 0.8355513004587252\n",
      "RANDOM_FOREST\n",
      "Avg accuracy : 0.7004768317984931\n",
      "Avg precission : 0.7961909547738694\n",
      "Avg recall : 0.7324212762423132\n",
      "Avg f1 : 0.7624684680802766\n",
      "ADA_BOOST\n",
      "Avg accuracy : 0.7862464965602591\n",
      "Avg precission : 0.851427135678392\n",
      "Avg recall : 0.8069359688038645\n",
      "Avg f1 : 0.8280957755660996\n",
      "GRADIENT_BOOST\n",
      "Avg accuracy : 0.8279292396170785\n",
      "Avg precission : 0.8966180904522613\n",
      "Avg recall : 0.8356194639427885\n",
      "Avg f1 : 0.8640632343038351\n",
      "XBOOST\n",
      "[20:57:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:57:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:58:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:59:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:00:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Avg accuracy : 0.8164597968914935\n",
      "Avg precission : 0.872532663316583\n",
      "Avg recall : 0.8360777893485599\n",
      "Avg f1 : 0.8526976124870872\n",
      "LGBM_CLASSIFIER\n",
      "Avg accuracy : 0.8303497979834746\n",
      "Avg precission : 0.892608040201005\n",
      "Avg recall : 0.8421957598968387\n",
      "Avg f1 : 0.8653049595175547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 921.6x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 921.6x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 921.6x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 921.6x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 921.6x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 921.6x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 921.6x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 921.6x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 921.6x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 921.6x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 921.6x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 921.6x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 921.6x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 921.6x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "components = [-1]\n",
    "filesPath = \"./datasets/\"\n",
    "for file in glob.glob(filesPath+\"*.csv\"):\n",
    "    for com in components:\n",
    "        if com == -1:\n",
    "            trainModel(file,'no',2)\n",
    "        else:\n",
    "            trainModel(file,'pca',com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '.\\\\Dataset-report'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ae3f589bcdac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0moverUnder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moverUnder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[1;32mc:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    876\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    879\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32mc:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mc:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1781\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1783\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yolan\\anaconda3\\envs\\directml\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '.\\\\Dataset-report'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "name_list = []\n",
    "total_list = []\n",
    "women_list = []\n",
    "men_list = []\n",
    "healthy_list = []\n",
    "pathological_list = []\n",
    "\n",
    "\n",
    "filePath = \"./datasets/\"\n",
    "for file in glob.glob(filePath+\"*.csv\"):\n",
    "        \n",
    "    target = \"healthy\"\n",
    "    dataframe = pd.read_csv(file)\n",
    "    y = dataframe[target]\n",
    "    X = dataframe.drop([target],axis=1)\n",
    "\n",
    "    overUnder = SMOTETomek()\n",
    "    X,y = overUnder.fit_resample(X,y)\n",
    "\n",
    "    \n",
    "    name_list.append(file.replace(\".csv\",\"\"))\n",
    "    total_list.append(X.shape[0])\n",
    "    if \"all\" in file:\n",
    "        a=X['sex'].values\n",
    "        women_list.append((a == 0).sum())\n",
    "        men_list.append((a == 1).sum())\n",
    "    else:\n",
    "        women_list.append(0)\n",
    "        men_list.append(0)\n",
    "        \n",
    "    healthy_list.append((y == 0).sum())\n",
    "    pathological_list.append((y == 1).sum())\n",
    "\n",
    "report = pd.DataFrame(np.column_stack([name_list, total_list,women_list,men_list, healthy_list, pathological_list]),\n",
    "                                            columns=['name', 'total', 'women','men','healthy', 'pathological'])\n",
    "report.to_csv(\"report.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
