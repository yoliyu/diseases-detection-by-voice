{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ef796d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c34a4198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict(model, k, X, y) -> Tuple[np.array, np.array, np.array]:\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=k)\n",
    "    model_ = cp.deepcopy(model)\n",
    "    acc_score = []\n",
    "    pre_score = []\n",
    "    # created scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    no_classes = len(np.unique(y))\n",
    "    \n",
    "    actual_classes = np.empty([0], dtype=int)\n",
    "    predicted_classes = np.empty([0], dtype=int)\n",
    "    predicted_proba = np.empty([0, no_classes]) \n",
    "\n",
    "    for train_ndx, test_ndx in kfold.split(X,y):\n",
    "\n",
    "        train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]\n",
    "\n",
    "        actual_classes = np.append(actual_classes, test_y)\n",
    "\n",
    "        # Standardize the dataset                                             \n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        # Fit on the train set only\n",
    "        scaler.fit(train_X)\n",
    "        # Apply to both the train set and the test set. \n",
    "        train_X = scaler.transform(train_X)\n",
    "        test_X = scaler.transform(test_X)\n",
    "      \n",
    "        # Apply PCA\n",
    "        pca = PCA()\n",
    "        # Fit on the train set only\n",
    "        pca.fit(train_X)\n",
    "        # Apply transform to both the train set and the test set. \n",
    "        train_X = pca.transform(train_X)\n",
    "        test_X = pca.transform(test_X)\n",
    "        \n",
    "    \n",
    "        model_.fit(train_X, train_y)\n",
    "        pred_values = model_.predict(test_X)\n",
    "        acc = accuracy_score(pred_values , test_y)\n",
    "        pre = precision_score(pred_values , test_y)\n",
    "        acc_score.append(acc)\n",
    "        pre_score.append(pre)\n",
    "        predicted_classes = np.append(predicted_classes, pred_values)\n",
    "        avg_acc_score = sum(acc_score)/k\n",
    "        avg_pre_score = sum (pre_score)/k\n",
    "\n",
    "        try:\n",
    "            predicted_proba = np.append(predicted_proba, model_.predict_proba(test_X), axis=0)\n",
    "        except:\n",
    "            predicted_proba = np.append(predicted_proba, np.zeros((len(test_X), no_classes), dtype=float), axis=0)\n",
    "\n",
    "    print('accuracy of each fold - {}'.format(acc_score))\n",
    "    print('Avg accuracy : {}'.format(avg_acc_score))\n",
    "    print('precission of each fold - {}'.format(pre_score))\n",
    "    print('Avg precission : {}'.format(avg_pre_score))\n",
    "\n",
    "    return actual_classes, predicted_classes, predicted_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70a1fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(actual_classes : np.array, predicted_classes : np.array, sorted_labels : list):\n",
    "\n",
    "    matrix = confusion_matrix(actual_classes, predicted_classes, labels=sorted_labels)\n",
    "    \n",
    "    plt.figure(figsize=(12.8,6))\n",
    "    sns.heatmap(matrix, annot=True, xticklabels=sorted_labels, yticklabels=sorted_labels, cmap=\"Blues\", fmt=\"g\")\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31834b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('X_phrase.csv')\n",
    "X = dataframe.iloc[:, 3:-1].values\n",
    "y = dataframe.iloc [:, 6374]\n",
    "\n",
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ac888",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  svm.SVC(kernel='rbf', C=100)\n",
    "actual_classes, predicted_classes, _ = cross_val_predict(model, k, X, y)\n",
    "plot_confusion_matrix(actual_classes, predicted_classes, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "077f701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.828 (0.027)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate pca with logistic regression algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# define the pipeline\n",
    "steps = [('norm', StandardScaler()), ('pca', PCA(n_components=120), ('m', svm.SVC(kernel='rbf', C=100))]\n",
    "model = Pipeline(steps=steps)\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "12c0e098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.679 (0.003)\n",
      ">2 0.718 (0.029)\n",
      ">3 0.736 (0.032)\n",
      ">4 0.736 (0.027)\n",
      ">5 0.733 (0.030)\n",
      ">6 0.730 (0.030)\n",
      ">7 0.727 (0.028)\n",
      ">8 0.732 (0.021)\n",
      ">9 0.732 (0.025)\n",
      ">10 0.727 (0.030)\n",
      ">11 0.720 (0.028)\n",
      ">12 0.732 (0.026)\n",
      ">13 0.723 (0.024)\n",
      ">14 0.723 (0.024)\n",
      ">15 0.725 (0.021)\n",
      ">16 0.737 (0.024)\n",
      ">17 0.738 (0.027)\n",
      ">18 0.740 (0.030)\n",
      ">19 0.747 (0.027)\n",
      ">20 0.746 (0.023)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pyplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-dd6de82ab31e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'>%s %.3f (%.3f)'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# plot model performance for comparison\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshowmeans\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pyplot' is not defined"
     ]
    }
   ],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(1,21):\n",
    "        steps =[('norm', StandardScaler()), ('pca', PCA(n_components=i)), ('m', svm.SVC(kernel='rbf', C=100))]\n",
    "        models[str(i)] = Pipeline(steps=steps)\n",
    "    return models\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "dataframe = pd.read_csv('X_phrase.csv')\n",
    "X = dataframe.iloc[:, 3:-1].values\n",
    "y = dataframe.iloc [:, 6374]\n",
    "\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a6807654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(1978, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ac8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
