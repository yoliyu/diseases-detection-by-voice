{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9856ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "sns.set() # Use seaborn's default style to make attractive graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa32ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(path,id):\n",
    "    dynamic_range=50\n",
    "    sound = parselmouth.Sound(path)\n",
    "    sound.pre_emphasize()\n",
    "    spectrogram = sound.to_spectrogram(window_length=0.05, \n",
    "                                   maximum_frequency=5500)\n",
    "    X, Y = spectrogram.x_grid(), spectrogram.y_grid()\n",
    "    sg_db = 10 * np.log10(spectrogram.values)\n",
    "    \n",
    "    fig = plt.figure(figsize=(16,12))\n",
    "    plt.pcolormesh(X, Y, sg_db, vmin=sg_db.max() - dynamic_range, cmap='afmhot')\n",
    "    plt.ylim([spectrogram.ymin, spectrogram.ymax])\n",
    "    plt.gca().set_axis_off()\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0,\n",
    "            hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)\n",
    "    fig.canvas.draw()\n",
    "    width, height = fig.get_size_inches() * fig.get_dpi()\n",
    "    numpy = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    plt.close()\n",
    "    \n",
    "    return numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e9a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_list = []\n",
    "healthy_list = []\n",
    "\n",
    "\n",
    "meta = pd.read_excel('../bd/SVD/META/SVD.xls', sheet_name='SVD')\n",
    "ids = meta['ID'].tolist()\n",
    "healthy = meta['Healthy'].tolist()\n",
    "sex = meta['Sex'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30717a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for wave_file in glob.glob(\"../bd/SVD/BD/PHRASE/*.wav\"):\n",
    "    x = wave_file.replace(\"../bd/SVD/BD/PHRASE\", \"\")\n",
    "    id = x.replace(\"-phrase.wav\", \"\")\n",
    "    id = id.replace(\"\\\\\", \"\")\n",
    "    placeId = ids.index(int(id))\n",
    "    print(id)\n",
    "    numpy = create_spectrogram(wave_file,id)\n",
    "    img.imsave(\"SVD/spectrograms_PHRASE/women/\"+id+\".png\",numpy) if sex[placeId]==\"m\" else img.imsave(\"SVD/spectrograms_PHRASE/men/\"+id+\".png\",numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7f1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.VGG16(\n",
    "    weights='imagenet',\n",
    "    input_shape=(320, 160, 3),\n",
    "    include_top=False)\n",
    "\n",
    "# Freeze base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create inputs with correct shape\n",
    "inputs = keras.Input(shape=(320, 160, 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# Add pooling layer or flatten layer\n",
    "x =  keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add final dense layer\n",
    "outputs = keras.layers.Dense(1, activation = 'softmax')(x)\n",
    "\n",
    "# Combine inputs and outputs to create model\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Important to use binary crossentropy and binary accuracy as we now have a binary classification problem\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True), metrics=[keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "# Create a data generator\n",
    "datagen_train = ImageDataGenerator(\n",
    "    samplewise_center=True,  # set each sample mean to 0\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.1,  # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False,\n",
    ")  # we don't expect Bo to be upside-down so we will not flip vertically\n",
    "\n",
    "# No need to augment validation data\n",
    "datagen_valid = ImageDataGenerator(samplewise_center=True)\n",
    "\n",
    "# load and iterate training dataset\n",
    "train_it = datagen_train.flow_from_directory(\n",
    "    \"SVD/spectrograms_PHRASE/train/\",\n",
    "    target_size=(320, 160),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"binary\",\n",
    "    batch_size=2,\n",
    ")\n",
    "\n",
    "# load and iterate validation dataset\n",
    "valid_it = datagen_valid.flow_from_directory(\n",
    "    \"SVD/spectrograms_PHRASE/valid/\",\n",
    "    target_size=(320, 160),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"binary\",\n",
    "    batch_size=2,\n",
    ")\n",
    "\n",
    "model.fit(train_it, steps_per_epoch=12, validation_data=valid_it, validation_steps=4, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee2eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1773e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
